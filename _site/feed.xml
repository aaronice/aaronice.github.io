<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Code Is Not Cold</title>
    <description>Blog on technology, life, thinking, etc.</description>
    <link>aaronice.github.io/</link>
    <atom:link href="aaronice.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 25 Feb 2016 15:09:10 -0800</pubDate>
    <lastBuildDate>Thu, 25 Feb 2016 15:09:10 -0800</lastBuildDate>
    <generator>Jekyll v3.1.1</generator>
    
      <item>
        <title>Safe password storage in Node.js</title>
        <description>&lt;h2 id=&quot;why-use-bcrypt&quot;&gt;Why Use &lt;em&gt;bcrypt&lt;/em&gt;?&lt;/h2&gt;

&lt;h2 id=&quot;why-not-use-md5-sha1-sha256-sha512-sha-3-etc&quot;&gt;Why Not Use MD5, SHA1, SHA256, SHA512, SHA-3, etc?&lt;/h2&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://codahale.com/how-to-safely-store-a-password/&quot;&gt;How To Safely Store A Password&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nakedsecurity.sophos.com/2013/11/20/serious-security-how-to-store-your-users-passwords-safely/&quot;&gt;Serious Security: How to store your users’ passwords safely&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Bcrypt&quot;&gt;bcrypt from Wikipedia&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ncb000gt/node.bcrypt.js&quot;&gt;bcrypt for NodeJs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 25 Feb 2016 04:00:00 -0800</pubDate>
        <link>aaronice.github.io/2016/02/25/safely-store-password-node/</link>
        <guid isPermaLink="true">aaronice.github.io/2016/02/25/safely-store-password-node/</guid>
        
        
      </item>
    
      <item>
        <title>Clustering in Node.js</title>
        <description>&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.carbonfive.com/2014/02/28/taking-advantage-of-multi-processor-environments-in-node-js/&quot;&gt;Taking Advantage of Multi-Processor Environments in Node.js&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 24 Feb 2016 04:00:00 -0800</pubDate>
        <link>aaronice.github.io/2016/02/24/node-js-cluster/</link>
        <guid isPermaLink="true">aaronice.github.io/2016/02/24/node-js-cluster/</guid>
        
        
      </item>
    
      <item>
        <title>ES6 Learning</title>
        <description>&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ericdouglas/ES6-Learning&quot;&gt;ECMAScript 6 Learning - List of resources to learn ECMAScript 6&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://ccoenraets.github.io/es6-tutorial/&quot;&gt;ECMAScript 2015 (ES6) Tutorial with Babel 6 and Webpack&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://gank.io/post/564151c1f1df1210001c9161&quot;&gt;给 JavaScript 初心者的 ES2015 实战&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 20 Feb 2016 04:00:00 -0800</pubDate>
        <link>aaronice.github.io/2016/02/20/es6-features/</link>
        <guid isPermaLink="true">aaronice.github.io/2016/02/20/es6-features/</guid>
        
        
      </item>
    
      <item>
        <title>React Performance Optimization</title>
        <description>&lt;p&gt;React Performance Optimization&lt;/p&gt;

&lt;p&gt;(To do)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://facebook.github.io/react/docs/perf.html&quot;&gt;Facebook React Performance Tools&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://facebook.github.io/react/docs/advanced-performance.html&quot;&gt;React Advanced Performance&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;[Optimizing React Performance using keys, component life cycle, and performance tools&lt;/td&gt;
          &lt;td&gt;Part 1](http://jaero.space/blog/react-performance-1)&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://kelle.co/react-perf-slides/#1&quot;&gt;Jaero Slides&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://jonmiles.github.io/react-performance-tests/react.html&quot;&gt;React.js Performance Tests&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 18 Feb 2016 04:00:00 -0800</pubDate>
        <link>aaronice.github.io/2016/02/18/react-performance-optimization/</link>
        <guid isPermaLink="true">aaronice.github.io/2016/02/18/react-performance-optimization/</guid>
        
        
      </item>
    
      <item>
        <title>Anti Anti-spider Strategy</title>
        <description>&lt;h1 id=&quot;the-anti-anti-scraping-strategy&quot;&gt;The Anti Anti-scraping Strategy&lt;/h1&gt;

&lt;p&gt;Before knowing how to prevent being blacklisted while scraping, we need to understand how a website detect web crawlers.&lt;/p&gt;

&lt;p&gt;There’re multiple anti-scraping mechanisms to distinguish a spider from a normal user. Some of the methods are&lt;a href=&quot;https://learn.scrapehero.com/how-to-prevent-getting-blacklisted-while-scraping/&quot;&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;
      &lt;p&gt;Unusual traffic/high download &lt;strong&gt;rate&lt;/strong&gt; especially from a &lt;strong&gt;single&lt;/strong&gt; client/or IP address within a short &lt;strong&gt;time&lt;/strong&gt; span.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;&lt;strong&gt;Repetitive&lt;/strong&gt; tasks performed on the website – based on an assumption that a human user won’t perform the same repetitive tasks all the time.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;Detection through &lt;strong&gt;honeypots&lt;/strong&gt; – these honeypots are usually links which &lt;strong&gt;aren’t visible&lt;/strong&gt; to a normal user but only to a spider. When a scraper/spider tries to access the link, the alarms are tripped.&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Corresponding to the anti-scraping mechanisms are the following strategies:&lt;/p&gt;

&lt;h2 id=&quot;ip-addresses-rotation&quot;&gt;IP Addresses Rotation&lt;/h2&gt;

&lt;p&gt;IP blacklisting is the perhaps the easiest way of anti-scraping. By creating a pool of IP addresses, and making requests using different IP, will make it harder for server to detect crawlers.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use a list of IP from proxy services
    &lt;ul&gt;
      &lt;li&gt;Randomly pick an IP for certain time interval&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cookie-rotation&quot;&gt;Cookie Rotation&lt;/h2&gt;
&lt;p&gt;Cookies are encrypted data stored in client side, some website use cookie to identify user. If a user client sends requests in high frequency, it’s possible to be identified as suspicious crawler, thus denied access.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Customize and manage a pool of cookies
    &lt;ul&gt;
      &lt;li&gt;Sending request to server without cookie headers, parse the package for set-cookie value; store it in cookie collector;&lt;/li&gt;
      &lt;li&gt;Get cookie from cookie collect and if the cookie is not usable, then delete it from cookie collector;&lt;/li&gt;
      &lt;li&gt;Manage the cookie collector with timestamp, in order for the spider to get the oldest cookie first each time.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Disable cookie
    &lt;ul&gt;
      &lt;li&gt;By disabling cookie, it may help prevent being banned by some websites which use cookie to identify crawlers.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;user-agent-imitation&quot;&gt;User-Agent Imitation&lt;/h2&gt;

&lt;p&gt;To disguise as browser, one of the approaches is to modify the User-Agent. User-Agent is a string in request header that contains user-agent information, such as the version of web browser, client, operating system etc.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Spoof the User-Agent by making a list of user agents and randomly pick one for each request. Setting the User-Agent to a common web
browser instead of using the default ones.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rate-limit&quot;&gt;Rate Limit&lt;/h2&gt;

&lt;p&gt;Slow down the crawling, treat the websites nicely, don’t overwhelm it, or DDoS the server.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Put some random sleeps between requests&lt;/li&gt;
  &lt;li&gt;Add some delays after crawling a number of pages&lt;/li&gt;
  &lt;li&gt;Use the lowest number of concurrent requests possible&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;be-careful-about-honeypots&quot;&gt;Be Careful About Honeypots&lt;/h2&gt;

&lt;p&gt;These honeypots usually are links that normal user can’t see but a spider can&lt;a href=&quot;https://learn.scrapehero.com/how-to-prevent-getting-blacklisted-while-scraping/&quot;&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/a&gt;. They might be having the CSS style “display:none”. Thus the detection of honeypots can be tricky.&lt;/p&gt;

&lt;h2 id=&quot;avoid-repetitive-crawling-pattern&quot;&gt;Avoid Repetitive Crawling Pattern&lt;/h2&gt;

&lt;p&gt;Some websites implemented intelligent anti-crawling mechanisms, thus a repetitive action will be likely detected as spider. To make a spider looks like a human, add random clicks, mouse movement, random actions etc. Using automated testing tool like Selenium may simulator normal “human actions”.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://learn.scrapehero.com/how-to-prevent-getting-blacklisted-while-scraping/&quot;&gt;HOW TO PREVENT GETTING BLACKLISTED WHILE SCRAPING&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.dianacody.com/2014/10/01/spider_5.html&quot;&gt;防止爬虫被墙的方法总结&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://medium.com/@Masutangu/%E5%BA%94%E5%AF%B9%E5%8F%8D%E7%88%AC%E8%99%AB%E4%B9%8B%E6%8D%A2cookie-d3b48b02d0e6&quot;&gt;应对反爬虫之换Cookie&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Mon, 15 Feb 2016 04:00:00 -0800</pubDate>
        <link>aaronice.github.io/2016/02/15/anti-anti-spider-strategy/</link>
        <guid isPermaLink="true">aaronice.github.io/2016/02/15/anti-anti-spider-strategy/</guid>
        
        
      </item>
    
      <item>
        <title>Modern Software Project Management - Agile Methodology</title>
        <description>&lt;p&gt;Individuals and Interactions » Processes and Tools
Working Software » comprehensive documentation
Customer Collaboration » Contract Negotiation
Responding to Change » Following a Plan&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://agilemethodology.org&quot;&gt;Agile Methodology&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 11 Feb 2016 04:00:00 -0800</pubDate>
        <link>aaronice.github.io/2016/02/11/agile-methodology/</link>
        <guid isPermaLink="true">aaronice.github.io/2016/02/11/agile-methodology/</guid>
        
        
      </item>
    
      <item>
        <title>What on earth is SOA?</title>
        <description>&lt;p&gt;To fill.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Service-oriented_architecture&quot;&gt;Wiki Service-oriented_architecture&lt;/a&gt;
# &lt;a href=&quot;http://aosabook.org/en/index.html&quot;&gt;The Architecture of Open Source Applications&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Tue, 09 Feb 2016 04:00:00 -0800</pubDate>
        <link>aaronice.github.io/2016/02/09/service-oriented-architecture/</link>
        <guid isPermaLink="true">aaronice.github.io/2016/02/09/service-oriented-architecture/</guid>
        
        
      </item>
    
      <item>
        <title>Interesting Machine Learning Projects</title>
        <description>&lt;p&gt;http://cs229.stanford.edu/projects2015.html#best&lt;/p&gt;
</description>
        <pubDate>Mon, 08 Feb 2016 04:00:00 -0800</pubDate>
        <link>aaronice.github.io/2016/02/08/machine-learning-projects/</link>
        <guid isPermaLink="true">aaronice.github.io/2016/02/08/machine-learning-projects/</guid>
        
        
      </item>
    
      <item>
        <title>Demystify Nginx</title>
        <description>&lt;h1 id=&quot;demystify-nginx&quot;&gt;Demystify Nginx&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;TO_DO&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://aosabook.org/en/nginx.html&quot;&gt;Nginx &lt;em&gt;by Andrew Alexeev&lt;/em&gt;&lt;/a&gt;
&lt;a href=&quot;https://en.wikipedia.org/wiki/Nginx&quot;&gt;Nginx &lt;em&gt;Wikipedia&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 07 Feb 2016 04:00:00 -0800</pubDate>
        <link>aaronice.github.io/2016/02/07/nginx/</link>
        <guid isPermaLink="true">aaronice.github.io/2016/02/07/nginx/</guid>
        
        
      </item>
    
      <item>
        <title>OWASP Security Top 10</title>
        <description>&lt;h1 id=&quot;owasp-top-10&quot;&gt;OWASP TOP 10&lt;/h1&gt;

&lt;p&gt;OWASP is abbreviation for Open Web Application Security Project.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The &lt;strong&gt;OWASP Top Ten&lt;/strong&gt; represents a broad consensus about what the most critical web application security flaws are.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#owasp-top-10&quot; id=&quot;markdown-toc-owasp-top-10&quot;&gt;OWASP TOP 10&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#sql-injection&quot; id=&quot;markdown-toc-sql-injection&quot;&gt;1. SQL Injection&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#session-hijacking&quot; id=&quot;markdown-toc-session-hijacking&quot;&gt;2. Session hijacking&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cross-site-scripting-xss&quot; id=&quot;markdown-toc-cross-site-scripting-xss&quot;&gt;3. Cross-site Scripting (XSS)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#parameter-manipulation-insecure-direct-object-reference&quot; id=&quot;markdown-toc-parameter-manipulation-insecure-direct-object-reference&quot;&gt;4. Parameter Manipulation (insecure direct object reference)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#insecure-configuration&quot; id=&quot;markdown-toc-insecure-configuration&quot;&gt;5. Insecure Configuration&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#insecure-storage&quot; id=&quot;markdown-toc-insecure-storage&quot;&gt;6. Insecure Storage&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#forcible-browsing&quot; id=&quot;markdown-toc-forcible-browsing&quot;&gt;7. Forcible Browsing&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cross-site-request-forgery-xsrf&quot; id=&quot;markdown-toc-cross-site-request-forgery-xsrf&quot;&gt;8. Cross-site request forgery (XSRF)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#vulnerable-components&quot; id=&quot;markdown-toc-vulnerable-components&quot;&gt;9. Vulnerable Components&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#unchecked-redirects&quot; id=&quot;markdown-toc-unchecked-redirects&quot;&gt;10. Unchecked Redirects&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#reference&quot; id=&quot;markdown-toc-reference&quot;&gt;Reference&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;sql-injection&quot;&gt;1. SQL Injection&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Reason&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Targets the back-end data stores via URL, forms, login boxes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Defense&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The best defense against SQL injection is use parameterized queries (prepared statements) for SQL queries within the code&lt;/li&gt;
  &lt;li&gt;No detailed database error message returned directly&lt;/li&gt;
  &lt;li&gt;Validate the input data before constructing SQL&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;session-hijacking&quot;&gt;2. Session hijacking&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Reason&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Network packet captured, SessionID being used, hijacker treated as user&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Defense&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Encryption of the site over HTTPS will help prevent session tokens from being stolen&lt;/li&gt;
  &lt;li&gt;Sensitive sites consider not only authentication but also the entire sites: Use SSL, HTTPS&lt;/li&gt;
  &lt;li&gt;Shorter idle timeouts&lt;/li&gt;
  &lt;li&gt;Help those who forgot to logout&lt;/li&gt;
  &lt;li&gt;Harder for hijackers to act&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cross-site-scripting-xss&quot;&gt;3. Cross-site Scripting (XSS)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Reason&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;User supplied input is properly escaped, or not verify it to be safe via input validation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Defense&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use proper re-encoding before redisplaying user input&lt;/li&gt;
  &lt;li&gt;Properly escape all untrusted data based on the HTML context&lt;/li&gt;
  &lt;li&gt;Positive or “whitelist” input validation&lt;/li&gt;
  &lt;li&gt;Auto-sanitization libraries&lt;/li&gt;
  &lt;li&gt;Content Security Policy (CSP)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;parameter-manipulation-insecure-direct-object-reference&quot;&gt;4. Parameter Manipulation (insecure direct object reference)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Reason&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Parameter values contained inside a URL being modified get different functionality or data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Defense&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Server-side validation&lt;/li&gt;
  &lt;li&gt;Central validation scheme&lt;/li&gt;
  &lt;li&gt;Independent business logic&lt;/li&gt;
  &lt;li&gt;Session variables&lt;/li&gt;
  &lt;li&gt;Storing data in session variables, no parameters in the URL to be tampered with&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;insecure-configuration&quot;&gt;5. Insecure Configuration&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Reason&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lack of standard hardening process for deployed infrastructure and software&lt;/li&gt;
  &lt;li&gt;No central account management mechanism in place on each server&lt;/li&gt;
  &lt;li&gt;No standardized and central process for patch management&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Defense&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Repeatable Hardening process&lt;/li&gt;
  &lt;li&gt;New server, repeatable hardening scripts&lt;/li&gt;
  &lt;li&gt;Patch Management&lt;/li&gt;
  &lt;li&gt;Regular Updates and Audits&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;insecure-storage&quot;&gt;6. Insecure Storage&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Reason&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sensitive data may be disclosed to unauthorized party&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Defense&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Determine what’s sensitive&lt;/li&gt;
  &lt;li&gt;Thread Modeling&lt;/li&gt;
  &lt;li&gt;Use known strong algorithms&lt;/li&gt;
  &lt;li&gt;Hashing&lt;/li&gt;
  &lt;li&gt;Use &amp;gt;=168bits, e.g. SHA-256, instead of MD5, SH0, SH1&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;forcible-browsing&quot;&gt;7. Forcible Browsing&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Reason&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Access by “guessing” the URL&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Defense&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Page Level Authorization&lt;/li&gt;
  &lt;li&gt;Each page checks to see if the user is authorized to have access&lt;/li&gt;
  &lt;li&gt;Programmed Authorization&lt;/li&gt;
  &lt;li&gt;Code and programming to determine a user’s authorization, includes coding roles and access policies&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cross-site-request-forgery-xsrf&quot;&gt;8. Cross-site request forgery (XSRF)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Reason&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Victim must be authenticated&lt;/li&gt;
  &lt;li&gt;Hacker must be able to make a XSRF URL, attack is blind&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Defense&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Decrease session timeouts&lt;/li&gt;
  &lt;li&gt;XSRF tokens, adding a secret, not automatically submitted, token to ALL sensitive requests&lt;/li&gt;
  &lt;li&gt;Server generates a token on each page load and stores it, when submits the form, it check if the token matches&lt;/li&gt;
  &lt;li&gt;Re-authentication&lt;/li&gt;
  &lt;li&gt;Asking user to re-authenticate before a sensitive transaction is a good way to verify the user and their intended actions&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;vulnerable-components&quot;&gt;9. Vulnerable Components&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Reason&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Vulnerable components are common, virtually every app has these issues; development team not enforcing components/libraries up-to-date&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Defense&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Automation checks periodically to check if libraries out-of-date&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;unchecked-redirects&quot;&gt;10. Unchecked Redirects&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;URL redirects exploited by hacker&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Defense&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Don’t use parameters (in URL), manage re-direction in code such as session data&lt;/li&gt;
  &lt;li&gt;Server side validation, check redirect URLs, use a whitelist&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.owasp.org/index.php/Category:OWASP_Top_Ten_Project&quot;&gt;OWASP Top 10&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.owasp.org/index.php/OWASP_Top_Ten_Cheat_Sheet&quot;&gt;OWASP_Top_Ten_Cheat_Sheet&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://nodegoat.herokuapp.com/tutorial&quot;&gt;OWASP Node Goat Tutorial: Fixing OWASP Top 10&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 18 Jan 2016 04:00:00 -0800</pubDate>
        <link>aaronice.github.io/2016/01/18/owasp-security-top-10/</link>
        <guid isPermaLink="true">aaronice.github.io/2016/01/18/owasp-security-top-10/</guid>
        
        
      </item>
    
  </channel>
</rss>
